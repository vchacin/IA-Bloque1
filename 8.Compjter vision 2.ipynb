{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De la visión artificial tradicional a la inteligencia artificial\n",
    "* Versión 1.1 *\n",
    "\n",
    "Para navegar hacia arriba y hacia abajo, puede usar las teclas de flecha hacia arriba y hacia abajo en su teclado <br />\n",
    "Para ejecutar código en este libro de trabajo, seleccione el bloque de código y presione ** Shift + Enter ** <br />\n",
    "Para editar el bloque de código, presione enter.\n",
    "\n",
    "Los códigos de este libro de trabajo son acumulativos. (Las variables definidas siguen estando disponibles hasta que se cierra el cuaderno) <br />\n",
    "¡Así que comience desde arriba y trabaje hacia abajo para evitar resultados inesperados!\n",
    "\n",
    "\n",
    "Para obtener más ayuda sobre el uso de Jupyter Notebook, puede hacer clic en Ayuda> Recorrido por la interfaz de usuario en el menú de arriba, <br />\n",
    "o visite https://jupyter-notebook.readthedocs.io/en/stable/ui_components.html\n",
    "\n",
    "Experimente y pruebe sus ideas, ¡porque esa es una de las formas más rápidas de aprender!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ¿Qué pasa si no necesitamos definir reglas manualmente para resolver un problema de clasificación?\n",
    "\n",
    "En el último taller, experimentó con varias técnicas básicas de procesamiento de imágenes y exploró cómo las computadoras podían \"ver\". Luego intentó que el sistema lo reconociera usando objetos que sostuvo frente a la cámara. Usted exploró una variedad de métodos, y muchos de sus métodos creativos probablemente involucraron la definición de reglas o lógica de \"si-si no\". Por ejemplo, reglas para lo que se consideraba colores, posición o una combinación de condiciones “autorizados”.\n",
    "\n",
    "Pero, ¿y si no necesita definir esas reglas manualmente?\n",
    "\n",
    "** Machine Learning ** es un subconjunto de la inteligencia artificial que se centra en la capacidad de las máquinas para aprender en función de los datos de entrenamiento. Aplicado al campo de la visión por computadora, ¿qué pasaría si pudiéramos hacer que la máquina aprenda qué es una imagen \"autorizada\" o \"no autorizada\", en lugar de tener que definir reglas para los códigos de color exactos?\n",
    "\n",
    "En el taller de hoy, exploraremos cómo las técnicas básicas de visión por computadora se pueden combinar con el aprendizaje automático para resolver una variedad de desafíos.\n",
    "1. Primero, pasaremos directamente a la creación de un modelo simple para ilustrar el aprendizaje automático.\n",
    "1. Luego daremos un paso atrás para ver los pasos involucrados en la construcción de un modelo de clasificación.\n",
    "1. A continuación, usamos modelos de clasificación para hacer inferencias y explorar la precisión.\n",
    "1. En el camino, busque y tome nota de las limitaciones y motivaciones de los diferentes métodos y técnicas utilizados.\n",
    "\n",
    "\n",
    "## Clasificación de una tarjeta en 1 de 3 categorías posibles\n",
    "\n",
    "Echemos un vistazo rápido al desafío de las \"tarjetas de acceso\" nuevamente. <br />\n",
    "Debajo hay 3 tarjetas (tarjetas rojas, verdes y negras) y una escena de fondo cuando no hay tarjetas colocadas frente a la cámara.\n",
    "La fila superior muestra las tarjetas colocadas más lejos, mientras que la fila inferior muestra las tarjetas colocadas muy cerca de la cámara web.\n",
    "\n",
    "\n",
    "<img src = \"images/cards.png\" style = \"float: left;\" />\n",
    "<div style = \"clear: both;\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analicemos el problema asumiendo que las tarjetas deben mantenerse cerca de la cámara web para su validación, entonces podría ser solo una cuestión de comparar los colores de cada tarjeta (imagen) para determinar cuál de las 3 tarjetas es."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Extracción de funciones: selección de las funciones que se utilizarán para ayudarnos a inferir\n",
    "\n",
    "Para este experimento, hemos decidido utilizar el color para ayudarnos a distinguir las cartas. Pero, ¿cómo seleccionaremos nuestras características de color? ¿Debemos seleccionar un punto en particular (por ejemplo, el centro de la imagen) o el color promedio de la imagen? ¿Deberíamos utilizar un canal en particular de la imagen BGR, o deberíamos convertirlo a escala de grises o cualquiera de los otros espacios de color?\n",
    "\n",
    "La selección de nuestras características afectará la solidez de su solución, y seleccionar \"características\" irrelevantes no sería útil.\n",
    "\n",
    "Por ejemplo, si intentamos utilizar el tamaño de la imagen de la cámara para determinar si se trata de una tarjeta autorizada, NO sería relevante ya que el tamaño de la imagen de la cámara no cambiará independientemente de la tarjeta que se coloque frente a la cámara.\n",
    "\n",
    "Puede intentar experimentar con diferentes funciones. <br />\n",
    "Pero mientras tanto, hagamos un experimento rápido usando el color promedio como característica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Let's read the images into memory\n",
    "red_card = cv2.imread(\"images/cardred_close.png\")\n",
    "green_card = cv2.imread(\"images/cardgreen_close.png\")\n",
    "black_card = cv2.imread(\"images/cardblack_close.png\")\n",
    "background = cv2.imread(\"images/cardnone.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Preprocesamiento y extracción de funciones **\n",
    "\n",
    "A veces, es posible que debamos hacer un preprocesamiento en nuestros datos de entrada para asegurarnos de que tengan un formato coherente que acepte el modelo.\n",
    "\n",
    "¿Cuáles son algunas formas en las que podemos preprocesar nuestros datos?\n",
    "1. Cambiar el tamaño a un tamaño estándar.\n",
    "2. Cambiar la orientación de la imagen.\n",
    "3. Conversión a un espacio de color particular.\n",
    "\n",
    "En este ejemplo en particular, nuestras imágenes de entrada cargadas ya están en un formato consistente (640x480) en el espacio de color BGR predeterminado. Pero nuestro modelo simple no usará todos los píxeles de la imagen como características para la predicción. En cambio, usaremos el color promedio como una característica para que el modelo infiera la clase a la que pertenece. Por lo tanto, a continuación definiremos un método para extraer el color promedio de cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una función para extraer nuestra característica (color promedio)\n",
    "def averagecolor(image):\n",
    "    return np.mean(image, axis=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos np.mean ya que el color promedio tiene 3 canales (y no un solo valor numérico). Para comprender cómo funciona np.mean, puede consultar la documentación en\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html#numpy.mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exploremos: ¿cuáles son las características extraídas (color promedio) de nuestras tarjetas roja y verde? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 27.35627604   4.48305664 154.21746094]\n"
     ]
    }
   ],
   "source": [
    "print (averagecolor(red_card))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119.53976563 133.40338216  61.1089388 ]\n"
     ]
    }
   ],
   "source": [
    "print (averagecolor(green_card))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Observa que los valores generados son diferentes? De hecho, sus valores están muy lejos unos de otros. ¡Esto es bueno! Esto significa que el color promedio es una buena característica para este simple problema.\n",
    "\n",
    "** Ahora, ¿y si hubiéramos elegido usar el tamaño de la imagen como nuestra característica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "print (red_card.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "print (green_card.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Sería capaz de distinguir la tarjeta roja y la tarjeta verde si solo supiera su forma?\n",
    "¡No! Ya que su forma es idéntica.\n",
    "\n",
    "¿Qué tal si supieras su colous promedio?\n",
    "\n",
    "Como podemos ver arriba, el color promedio de la tarjeta roja y la tarjeta verde son bastante diferentes. ¡Pero el tamaño de la imagen de ambas tarjetas es exactamente el mismo! Dado que queremos usar las funciones para diferenciar las cartas, seguiremos utilizando el color promedio para ayudarnos a inferir el tipo de cartas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora crearemos variables para ingresar el valor de color promedio y la etiqueta de cada archivo de imagen. Usaremos esto más adelante para el entrenamiento de modelos. ¿Recuerda cómo se realiza este entrenamiento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('red', array([ 27.35627604,   4.48305664, 154.21746094]))\n",
      "('green', array([119.53976563, 133.40338216,  61.1089388 ]))\n",
      "('black', array([70.36474609, 61.85563477, 67.1775651 ]))\n",
      "('none', array([247.9326888 , 241.13666016, 241.89832357]))\n"
     ]
    }
   ],
   "source": [
    "# Store the features (average color) and corresponding label (red/green/black/none) for classification\n",
    "trainX = []\n",
    "trainY = []\n",
    "\n",
    "# loop through the cards and print the average color\n",
    "for (card,label) in zip((red_card,green_card,black_card,background),(\"red\",\"green\",\"black\",\"none\")):\n",
    "    print((label, averagecolor(card)))\n",
    "    trainX.append(averagecolor(card))\n",
    "    trainY.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerde del taller anterior cómo la representación de la matriz tiene el orden predeterminado [Azul, Verde, Rojo]\n",
    "\n",
    "Observe cómo la tarjeta roja tiene un valor de rojo mucho más alto que el resto. Para la tarjeta verde, vemos que tiene valores más altos de azul y verde, y no solo verde.\n",
    "\n",
    "trainX ahora almacena los vectores de características (características) y trainY almacena las etiquetas correspondientes.\n",
    "\n",
    "Si se pregunta qué se almacena dentro de trainX y qué se almacena dentro de trainY, imprima las matrices y compruébelo usted mismo (comparándolas con las impresiones anteriores). Es útil que comprenda cómo se almacenan los datos en este punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 27.35627604,   4.48305664, 154.21746094]), array([119.53976563, 133.40338216,  61.1089388 ]), array([70.36474609, 61.85563477, 67.1775651 ]), array([247.9326888 , 241.13666016, 241.89832357])]\n",
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "print(trainX)\n",
    "print(np.array(trainX).shape)      #Note how the 3 channels are stored in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['red', 'green', 'black', 'none']\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "print(trainY)\n",
    "print(np.array(trainY).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si toma más imágenes, puede encontrar que el color promedio no siempre es el mismo valor exacto y probablemente fluctuará debido a las condiciones de iluminación y la configuración de la cámara. Por lo tanto, entrenar un modelo generalmente implica más que unas pocas imágenes. Pero usaremos solo estas pocas imágenes solo para ilustrar el concepto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Introcción del algoritmo del vecino más cercano (kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando colocamos una nueva tarjeta frente a la cámara, queremos determinar a cuál de estas tarjetas se parece más. En lugar de definir los códigos de color exactos, podríamos abordarlo desde el ángulo de \"** ¿A cuál de nuestras tarjetas existentes conocidas es más similar a la nueva tarjeta? **\"\n",
    "\n",
    "El concepto de k-vecinos más cercanos es buscar en el conjunto de imágenes etiquetadas k imágenes más similares a la nueva imagen. Y basándose en las etiquetas de esas imágenes similares, predice la etiqueta de la nueva imagen.\n",
    "\n",
    "Realizaremos un experimento a continuación para k = 1. Es decir, encontrar 1 imagen con el color promedio más similar al de la nueva imagen. Y use la etiqueta de esa imagen para predecir la etiqueta de la nueva imagen.\n",
    "\n",
    "¡Analicemos cómo se hace esto!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primero leemos la nueva imagen en la memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_card = cv2.imread(\"images/test/16.png\")\n",
    "new_card_features = averagecolor(new_card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcula las distancias entre las características (color promedio) de esa nueva imagen y las características de las imágenes que conocemos\n",
    "Lea sobre linealg.norm [aquí] (https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.norm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117.79791641023513, 113.43645699355922, 33.497714831624535, 340.3000785919897]\n"
     ]
    }
   ],
   "source": [
    "calculated_distances = []\n",
    "for card in (trainX):\n",
    "    calculated_distances.append(np.linalg.norm(new_card_features-card))\n",
    "    \n",
    "print (calculated_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y aquí está el resultado de a qué tarjeta es más similar:\n",
    "¿Puedes adivinar con solo mirar las distancias calculadas arriba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black\n"
     ]
    }
   ],
   "source": [
    "print(trainY[np.argmin(calculated_distances)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abra la subcarpeta de imágenes / prueba y verifique los colores reales de las imágenes respectivas.\n",
    "\n",
    "Tenga en cuenta que la medida de distancia que usamos fue \"np.linalg.norm ()\". Puede leer más sobre esto en https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.norm.html o busque en Internet \"Distancia euclidiana\". En términos simples, puede tomarlo como una medida de cuán similares son los valores de matriz de (new_card_features) y (card).\n",
    "\n",
    "Tómese un tiempo para comprender también lo que hace la última línea. Recuerde lo que está almacenado dentro de trainY en la sección 1.1.\n",
    "\n",
    "Compruebe lo que se almacena dentro de las distancias calculadas.\n",
    "¿Qué hace np.argmin?\n",
    "\n",
    "Sugerencia: busque la documentación de numpy.argmin si es necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117.79791641023513, 113.43645699355922, 33.497714831624535, 340.3000785919897]\n"
     ]
    }
   ],
   "source": [
    "print(calculated_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(np.argmin(calculated_distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['red', 'green', 'black', 'none']\n"
     ]
    }
   ],
   "source": [
    "print(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black\n"
     ]
    }
   ],
   "source": [
    "print(trainY[np.argmin(calculated_distances)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intentemos probar otra tarjeta\n",
    "¡Recuerde revisar su carpeta para asegurarse de que el modelo realmente pueda predecir lo que queremos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red\n"
     ]
    }
   ],
   "source": [
    "# Primero leemos la nueva imagen en la memoria\n",
    "new_card = cv2.imread(\"images/test/36.png\")\n",
    "new_card_features = averagecolor(new_card)\n",
    "\n",
    "\n",
    "# Calcule las distancias entre las características (color promedio) de esa nueva imagen frente a las características de las imágenes que conocemos\n",
    "calculated_distances = []\n",
    "for card in (trainX):\n",
    "    calculated_distances.append(np.linalg.norm(new_card_features-card))\n",
    "\n",
    "# Y aquí está el resultado de a qué tarjeta es más similar:\n",
    "print(trainY[np.argmin(calculated_distances)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué tal otra tarjeta?\n",
    "¡Recuerde revisar su carpeta para asegurarse de que el modelo realmente pueda predecir lo que queremos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green\n"
     ]
    }
   ],
   "source": [
    "# First we read the new image into memory\n",
    "new_card = cv2.imread(\"images/test/56.png\")\n",
    "new_card_features = averagecolor(new_card)\n",
    "\n",
    "# Calculate the distances between the features (average color) of that new image against the features of the images we know\n",
    "calculated_distances = []\n",
    "for card in (trainX):\n",
    "    calculated_distances.append(np.linalg.norm(new_card_features-card))\n",
    "\n",
    "# And here is the result of the which card it is most similar to:\n",
    "print(trainY[np.argmin(calculated_distances)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intentemos clasificar todas las tarjetas de prueba\n",
    "\n",
    "¡Nada mal! Parece que nuestro modelo simplista ha clasificado correctamente las cartas hasta ahora.\n",
    "\n",
    "Intentemos recorrer y clasificar todas las tarjetas en la subcarpeta de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Ground truth for the test images. Open the folder on your computer to see the images.\n",
    "realtestY = np.array([\"black\",\"black\",\"black\",\"black\",\"black\",\n",
    "                     \"red\",\"red\",\"red\",\"red\",\"red\",\n",
    "                     \"green\",\"green\",\"green\",\"green\",\"green\",\n",
    "                     \"none\",\"none\",\"none\",\"none\",\"none\"])\n",
    "def evaluateaccuracy(filenames,predictedY):\n",
    "    predictedY = np.array(predictedY)\n",
    "    if (np.sum(realtestY!=predictedY)>0):\n",
    "        print (\"Wrong Predictions: (filename, labelled, predicted) \")\n",
    "        print (np.dstack([filenames,realtestY,predictedY]).squeeze()[(realtestY!=predictedY)])\n",
    "    # Calculate those predictions that match (correct), as a percentage of total predictions\n",
    "    return \"Correct :\"+ str(np.sum(realtestY==predictedY)) + \". Wrong: \"+str(np.sum(realtestY!=predictedY)) + \". Correctly Classified: \" + str(np.sum(realtestY==predictedY)*100/len(predictedY))+\"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Le sorprendió que no hubiera resultado para el bloque de código anterior? Eso es porque solo definimos la función para hacer la evaluación de precisión. Para obtener más información sobre las funciones en Python, puede visitar [este enlace] (https://www.datacamp.com/community/tutorials/functions-python-tutorial)\n",
    "\n",
    "Ejecutemos el bloque de código a continuación para ver las salidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.png: none\n",
      "76.png: none\n",
      "60.png: green\n",
      "59.png: green\n",
      "58.png: none\n",
      "17.png: black\n",
      "16.png: black\n",
      "39.png: red\n",
      "38.png: red\n",
      "20.png: black\n",
      "36.png: red\n",
      "37.png: red\n",
      "18.png: black\n",
      "19.png: black\n",
      "56.png: green\n",
      "57.png: green\n",
      "80.png: none\n",
      "40.png: red\n",
      "78.png: none\n",
      "79.png: none\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       black       0.00      0.00      0.00         5\n",
      "       green       0.25      0.20      0.22         5\n",
      "        none       0.50      0.60      0.55         5\n",
      "         red       0.40      0.40      0.40         5\n",
      "\n",
      "    accuracy                           0.30        20\n",
      "   macro avg       0.29      0.30      0.29        20\n",
      "weighted avg       0.29      0.30      0.29        20\n",
      "\n",
      "\n",
      "Wrong Predictions: (filename, labelled, predicted) \n",
      "[['77.png' 'black' 'none']\n",
      " ['76.png' 'black' 'none']\n",
      " ['60.png' 'black' 'green']\n",
      " ['59.png' 'black' 'green']\n",
      " ['58.png' 'black' 'none']\n",
      " ['17.png' 'red' 'black']\n",
      " ['16.png' 'red' 'black']\n",
      " ['20.png' 'red' 'black']\n",
      " ['36.png' 'green' 'red']\n",
      " ['37.png' 'green' 'red']\n",
      " ['18.png' 'green' 'black']\n",
      " ['19.png' 'green' 'black']\n",
      " ['57.png' 'none' 'green']\n",
      " ['40.png' 'none' 'red']]\n",
      "Correct :6. Wrong: 14. Correctly Classified: 30.0%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"images/test/\"\n",
    "predictedY = []\n",
    "filenames = []\n",
    "for filename in os.listdir(path):\n",
    "    img = cv2.imread(path+filename)\n",
    "    img_features = averagecolor(img)\n",
    "    calculated_distances = []\n",
    "    for card in (trainX):\n",
    "        calculated_distances.append(np.linalg.norm(img_features-card))\n",
    "    prediction = trainY[np.argmin(calculated_distances)]\n",
    "    \n",
    "    print (filename + \": \" + prediction) #Print out the inferences\n",
    "    filenames.append(filename)\n",
    "    predictedY.append(prediction)\n",
    "\n",
    "# Evaluar la precisión (el paquete sklearn proporciona un informe útil)\n",
    "print ()\n",
    "print(classification_report(realtestY, predictedY))\n",
    "\n",
    "# Evaluar la precisión (nuestro propio método personalizado para generar los nombres de archivo de las entradas mal clasificadas)\n",
    "print ()\n",
    "print (evaluateaccuracy(filenames,predictedY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ¿Qué significa precisión y recuperación? **\n",
    "¿Recuerdas que pasamos por estos durante la etapa de adquisición?\n",
    "\n",
    "Recuerde los conceptos de verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos.\n",
    "\n",
    "Por ejemplo, si estamos evaluando la clase roja:\n",
    "- Si clasifica una imagen roja correctamente como roja, eso es un verdadero positivo.\n",
    "- Si clasifica incorrectamente una imagen roja como negra, es un falso negativo.\n",
    "- Si clasifica otra imagen que no es roja como roja, eso es un falso positivo.\n",
    "- Si clasifica una imagen que no es roja correctamente como no roja, eso es un verdadero negativo.\n",
    "\n",
    "La precisión es el número de verdaderos positivos dividido por (verdaderos positivos + falsos positivos), es decir, cuántos de los que se clasificaron en rojo eran en realidad rojos.\n",
    "\n",
    "La recuperación es el número de verdaderos positivos dividido por (verdaderos positivos + falsos negativos), es decir, cuántas imágenes rojas se clasificaron correctamente en rojo cuando trató de obtener todas las imágenes rojas.\n",
    "\n",
    "Para leer más sobre precisión y recuperación, puede buscar en Internet como de costumbre o visitar https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Investiguemos la imagen mal clasificada **\n",
    "\n",
    "Abra esa carpeta y verifique las imágenes.\n",
    "Parece que 58.png se clasificó incorrectamente. ¿Por qué?\n",
    "\n",
    "58.png\n",
    "\n",
    "<img src = \"images/test/58.png\" style = \"width: 400px; float: left;\" />\n",
    "<div style = \"clear: both;\"> </div>\n",
    "\n",
    "Recuerde nuestro conjunto inicial de imágenes de entrenamiento. <br />\n",
    "58.png se ve mucho más brillante que la imagen de entrenamiento para \"verde\", lo que puede sugerir por qué se confundió con \"ninguno\" (que era el \"más brillante\" entre las 4 imágenes de entrenamiento)\n",
    "\n",
    "<img src = \"images/cards.png\" style = \"float: left;\" />\n",
    "<div style = \"clear: both;\"> </div> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nosotros, como humanos, es fácil para nosotros decir que 58.png debe clasificarse como verde.\n",
    "\n",
    "Sin embargo, recuerde que la función que usamos para \"entrenar\" el sistema era \"color promedio\" y solo proporcionamos una imagen de entrenamiento.\n",
    "\n",
    "Parece que el color promedio de 58.png está más cerca del color promedio del fondo (background.png) en lugar de la imagen de entrenamiento (cardgreen_close.png).\n",
    "\n",
    "Se dejará como ejercicio para que calcule el color promedio de las imágenes respectivamente y descubra por qué se clasificó incorrectamente. Ese será su Desafío 1 más adelante en este cuaderno.\n",
    "\n",
    "Mientras tanto, ¿puede pensar en una forma de mejorar el modelo?\n",
    "\n",
    "### ¡Abre la carpeta de imágenes de prueba!\n",
    "Puede abrir la carpeta de imágenes de prueba. ¿Parecen estar bajo diferentes condiciones de iluminación? Hasta ahora, solo entrenamos nuestro sistema usando un solo ejemplo para cada tarjeta de color. ¿Crees que podría ayudar tener más imágenes de entrenamiento?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Entrenamiento con más ejemplos\n",
    " \n",
    "¿Qué tal entrenarlo con más muestras? <br />\n",
    "Recuerde lo que hicimos en la sección 1.1 para obtener trainX y trainY. Si lo ha olvidado, vuelva a visitar la sección 1.1 para comprender mejor el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training images for the label: red\n",
      "Loading training images for the label: green\n",
      "Loading training images for the label: black\n",
      "Loading training images for the label: none\n"
     ]
    }
   ],
   "source": [
    "trainX2 = []\n",
    "trainY2 = []\n",
    "import os\n",
    "\n",
    "# Let's loop through the training images in the 4 folders in the image subdirectory\n",
    "path = \"images/\"\n",
    "for label in ('red','green','black','none'):\n",
    "    print (\"Loading training images for the label: \"+label)\n",
    "    \n",
    "    #Load all images inside the subfolder\n",
    "    for filename in os.listdir(path+label+\"/\"): \n",
    "        img = cv2.imread(path+label+\"/\"+filename)\n",
    "        img_features = averagecolor(img)\n",
    "        trainX2.append(img_features)\n",
    "        trainY2.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea: ¿Cuántas imágenes usamos para entrenar nuestro modelo ahora?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print (len(# Su código aquí))\n",
    "print (len(# Su código aquí))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea: ¡Consulta con las subcarpetas!\n",
    "Abra las subcarpetas rojo, verde, negro y ninguno en el directorio de imágenes de su computadora. ¿Cuántas imágenes cargamos de cada carpeta?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Después de haber cargado más imágenes de entrenamiento, volvamos a ejecutar la prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.png: none\n",
      "76.png: none\n",
      "60.png: green\n",
      "59.png: green\n",
      "58.png: green\n",
      "17.png: black\n",
      "16.png: black\n",
      "39.png: red\n",
      "38.png: red\n",
      "20.png: black\n",
      "36.png: red\n",
      "37.png: red\n",
      "18.png: black\n",
      "19.png: black\n",
      "56.png: green\n",
      "57.png: green\n",
      "80.png: none\n",
      "40.png: red\n",
      "78.png: none\n",
      "79.png: none\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       black       0.00      0.00      0.00         5\n",
      "       green       0.20      0.20      0.20         5\n",
      "        none       0.60      0.60      0.60         5\n",
      "         red       0.40      0.40      0.40         5\n",
      "\n",
      "    accuracy                           0.30        20\n",
      "   macro avg       0.30      0.30      0.30        20\n",
      "weighted avg       0.30      0.30      0.30        20\n",
      "\n",
      "Wrong Predictions: (filename, labelled, predicted) \n",
      "[['77.png' 'black' 'none']\n",
      " ['76.png' 'black' 'none']\n",
      " ['60.png' 'black' 'green']\n",
      " ['59.png' 'black' 'green']\n",
      " ['58.png' 'black' 'green']\n",
      " ['17.png' 'red' 'black']\n",
      " ['16.png' 'red' 'black']\n",
      " ['20.png' 'red' 'black']\n",
      " ['36.png' 'green' 'red']\n",
      " ['37.png' 'green' 'red']\n",
      " ['18.png' 'green' 'black']\n",
      " ['19.png' 'green' 'black']\n",
      " ['57.png' 'none' 'green']\n",
      " ['40.png' 'none' 'red']]\n",
      "Correct :6. Wrong: 14. Correctly Classified: 30.0%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"images/test/\"\n",
    "filenames = []\n",
    "predictedY = []\n",
    "for filename in os.listdir(path):\n",
    "    img = cv2.imread(path+filename)\n",
    "    img_features = averagecolor(img)\n",
    "    calculated_distances = []\n",
    "    for card in (trainX2):\n",
    "        calculated_distances.append(np.linalg.norm(img_features-card))\n",
    "    prediction =  trainY2[np.argmin(calculated_distances)]\n",
    "    \n",
    "    print (filename + \": \" + prediction)\n",
    "    filenames.append(filename)\n",
    "    predictedY.append(prediction)\n",
    "\n",
    "# Evaluate Accuracy (the sklearn package provides a useful report)\n",
    "print ()\n",
    "print(classification_report(realtestY, predictedY))\n",
    "\n",
    "# Evaluate Accuracy\n",
    "print (evaluateaccuracy(filenames,predictedY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ¿Qué acabamos de hacer? **\n",
    "\n",
    "Acabamos de ver cómo \"entrenamos\" el modelo para el kNN en la sección 1.1, y luego usamos el modelo para predecir a qué clase pertenecía la nueva tarjeta en la sección 1.2. Luego fuimos más allá en la sección 1.3 para explorar cómo el aumento de los datos de entrenamiento podría ayudar a mejorar la precisión, eliminando el error anterior de clasificar erróneamente \"58.png\" como ninguno cuando en realidad era verde.\n",
    "\n",
    "Usamos un ejemplo muy simplificado del algoritmo kNN que encuentra los k Vecinos más cercanos para predecir la clase de la nueva imagen basada en sus vecinos más cercanos. En el ejemplo anterior, el valor de k era 1. Por lo tanto, solo buscamos el vecino más cercano (el vecino con la distancia calculada más pequeña) y predijimos el valor de la imagen de prueba según la clase del vecino más cercano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tómese un momento para reflexionar\n",
    "\n",
    "¿Cómo se compara este método con los métodos utilizados en el taller anterior?\n",
    "\n",
    "¿Necesitó más o menos líneas de código? ¿Prefiere definir las reglas o dejar que la máquina aprenda por sí misma? Para la mayoría de ustedes, probablemente les resulte más fácil proporcionar un conjunto de imágenes de entrenamiento que tener que definir las reglas manualmente. Si le resultó más fácil definir las reglas y aún tenía un sistema bastante sólido, ¿qué técnicas utilizó?\n",
    "\n",
    "¿Cómo podemos mejorar aún más el sistema? ¿Sería aún mejor una combinación de enfoques? ¿Funcionará esto con todo tipo de imágenes? ¿Por qué o por qué no? Escriba sus notas en la Guía de actividades del estudiante.\n",
    "\n",
    "<br />\n",
    "<video controls src=\"images/black_red_green.mp4\" style=\"width:400px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pasos básicos para crear un modelo de clasificación\n",
    "\n",
    "En la sección 1, nos lanzamos rápidamente a implementar un modelo de clasificación muy simple basado en el algoritmo kNN.\n",
    "En la práctica, el entrenamiento de modelos de visión por computadora generalmente se realiza utilizando marcos como Keras, Tensorflow, Caffe y MXNet, o bibliotecas como Scikit-Learn para Python. Estos marcos y bibliotecas contienen varias herramientas y facilitan el trabajo con conjuntos de datos y algoritmos más grandes sin tener que codificar todo desde cero.\n",
    "\n",
    "La capacitación puede llevar horas, días o incluso semanas, y a menudo requiere máquinas con GPU y capacidades informáticas más potentes. El modelo que construimos para kNN fue simplista usando matrices numpy, con el fin de ilustrar los conceptos.\n",
    "\n",
    "Exploremos ahora los pasos que normalmente se requieren para crear un modelo de clasificación (algunos de los cuales ya se realizaron en este ejercicio):\n",
    "1. Recopilación de datos\n",
    "1. Preparación de datos (limpieza, etiquetado, etc.)\n",
    "1. Dividir los datos en un conjunto de entrenamiento y un conjunto de prueba\n",
    "1. Seleccionar un algoritmo y entrenar un modelo\n",
    "1. Evaluación del desempeño\n",
    "\n",
    "Seleccionar el algoritmo a utilizar fue solo uno de los 5 pasos. Para los algoritmos de aprendizaje automático, la preparación de datos es muy importante. Si introduce información incorrecta, el modelo resultará naturalmente incorrecto. Los datos deben ser representativos y las características utilizadas deben ser relevantes para su propósito. De lo contrario, es posible que obtenga resultados muy poco fiables.\n",
    "\n",
    "Del mismo modo, cualquier preprocesamiento previo y las funciones que utilice para el modelo son importantes. Imagínese tratando de entrenar un modelo que reconoce flores de diferentes colores pero solo usando imágenes en escala de grises (dejando de lado las características de color importantes). Por el contrario, para el reconocimiento óptico de caracteres (OCR), el color puede no ser muy útil y puede que no se incluya en las funciones seleccionadas para el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Eso fue kNN, ¿qué tal Support Vector Machines?\n",
    "\n",
    "Si lo piensa bien, el algoritmo k-Nemost-Neighbor realmente no aprendió mucho, básicamente almacenó los datos de entrenamiento e hizo una búsqueda cada vez que se requería una inferencia en una nueva imagen.\n",
    "\n",
    "En tu clase de matemáticas, ¿recuerdas haber aprendido a derivar la ecuación de una línea ** y = mx + c? **\n",
    "\n",
    "¿Qué pasaría si también pudiéramos derivar una ecuación o fórmula que pudiera usarse para predecir las diferentes clases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué son los vectores de soporte?\n",
    "\n",
    "Imagina que necesitas clasificar O de X. ¿Podrías dibujar una sola línea que separe mejor todas las X de la O?\n",
    "\n",
    "<img src = \"images/svm1.jpg\" style = \"width: 300px; float: left;\" />\n",
    "<div style = \"clear: both;\"> </div>\n",
    "\n",
    "Quizás podríamos dibujar una línea (línea azul debajo). Y este es un ejemplo simple de un vector de soporte. Cualquier cosa a la izquierda / arriba de la línea podría clasificarse como X, y cualquier cosa a la derecha / abajo de la línea podría clasificarse como O.\n",
    "\n",
    "<img src = \"images/svm2.jpg\" style = \"width: 300px; float: left;\" />\n",
    "<div style = \"clear: both;\"> </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: Las matemáticas detrás de SVM estarán fuera del alcance de este taller, pero se le anima a leer más. https://www.svm-tutorial.com/2014/11/svm-understanding-math-part-1/ (En el enlace, se ilustra con diagramas cómo un solo vector lineal puede separar 2 clases distintas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasemos a explorar cómo funcionan las máquinas de vectores de soporte (SVM) en la práctica, haciendo uso de la biblioteca python scikit-learn. Primero, \"deriva la ecuación\" del vector de soporte, luego \"usa la ecuación\" para ejecutar las predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primero se entrena el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since SVM uses numerical values, we first encode our labels into numerical\n",
    "from sklearn.preprocessing import LabelEncoder  #encode labels into numerical\n",
    "encoder = LabelEncoder()                        #encode labels into numerical\n",
    "encodedtrainY2 = encoder.fit_transform(trainY2) #encode labels into numerical\n",
    "\n",
    "from sklearn import svm\n",
    "model = svm.SVC(gamma=\"scale\", decision_function_shape='ovr')\n",
    "model.fit(trainX2, encodedtrainY2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué hace LabelEncoder? Veamos el resultado de la función.\n",
    "Puede leer más sobre LabelEncoder [aquí] (https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print (encodedtrainY2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La comprensión profunda de SVM está más allá del alcance de este módulo, pero no dude en obtener más información [aquí] (https://medium.com/all-things-ai/in-depth-parameter-tuning-for-svc- 758215394769)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, hemos obtenido nuestro modelo SVM.\n",
    "\n",
    "### ¡Ejecutemos las predicciones!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.png: none\n",
      "76.png: none\n",
      "60.png: green\n",
      "59.png: green\n",
      "58.png: green\n",
      "17.png: black\n",
      "16.png: black\n",
      "39.png: red\n",
      "38.png: red\n",
      "20.png: black\n",
      "36.png: red\n",
      "37.png: red\n",
      "18.png: black\n",
      "19.png: black\n",
      "56.png: green\n",
      "57.png: green\n",
      "80.png: none\n",
      "40.png: red\n",
      "78.png: none\n",
      "79.png: none\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       black       0.00      0.00      0.00         5\n",
      "       green       0.20      0.20      0.20         5\n",
      "        none       0.60      0.60      0.60         5\n",
      "         red       0.40      0.40      0.40         5\n",
      "\n",
      "    accuracy                           0.30        20\n",
      "   macro avg       0.30      0.30      0.30        20\n",
      "weighted avg       0.30      0.30      0.30        20\n",
      "\n",
      "Wrong Predictions: (filename, labelled, predicted) \n",
      "[['77.png' 'black' 'none']\n",
      " ['76.png' 'black' 'none']\n",
      " ['60.png' 'black' 'green']\n",
      " ['59.png' 'black' 'green']\n",
      " ['58.png' 'black' 'green']\n",
      " ['17.png' 'red' 'black']\n",
      " ['16.png' 'red' 'black']\n",
      " ['20.png' 'red' 'black']\n",
      " ['36.png' 'green' 'red']\n",
      " ['37.png' 'green' 'red']\n",
      " ['18.png' 'green' 'black']\n",
      " ['19.png' 'green' 'black']\n",
      " ['57.png' 'none' 'green']\n",
      " ['40.png' 'none' 'red']]\n",
      "Correct :6. Wrong: 14. Correctly Classified: 30.0%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"images/test/\"\n",
    "filenames = []\n",
    "predictedY = []\n",
    "for filename in os.listdir(path):\n",
    "    img = cv2.imread(path+filename)\n",
    "    img_features = averagecolor(img)\n",
    "    prediction = model.predict([img_features])[0]\n",
    "    \n",
    "    #decode the prediction\n",
    "    prediction = encoder.inverse_transform([prediction])[0]\n",
    "    \n",
    "    print (filename + \": \" + prediction)\n",
    "    filenames.append(filename)\n",
    "    predictedY.append(prediction)\n",
    "\n",
    "# Evaluate Accuracy (the sklearn package provides a useful report)\n",
    "print ()\n",
    "print(classification_report(realtestY, predictedY))\n",
    "\n",
    "# Evaluate Accuracy\n",
    "print (evaluateaccuracy(filenames,predictedY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuál es más preciso?\n",
    "\n",
    "¿Crees que SVM es más eficaz para obtener clasificaciones más correctas que kNN o viceversa?\n",
    "\n",
    "Depende del problema. Y para SVM, también hay otros parámetros que deberán ajustarse y que están fuera del alcance de este taller. Estos parámetros guiarán el proceso de generación del modelo. Por ejemplo, el modelo necesita saber qué tipo de vector de soporte generar. Una \"línea recta\" podría funcionar para algunos conjuntos de datos, pero para otros, podríamos necesitar una curva o vectores de soporte más complejos.\n",
    "\n",
    "A modo de ilustración, imagínese tratando de ajustar una línea recta para clasificar las O y las X a continuación. Quizás necesite una ecuación para un círculo.\n",
    "\n",
    "<img src = \"images/svm3.jpg\" style = \"width: 400px; float: left;\" />\n",
    "<div style = \"clear: both;\"> </div>\n",
    "\n",
    "Puede consultar los enlaces al final de esta sección si desea obtener más información.\n",
    "\n",
    "Hasta este punto, entrené el modelo usando trainX2 y trainY2, luego probé nuestro modelo con un conjunto separado de imágenes y pareció funcionar bien. Sin embargo, trabajar bien en un equipo de prueba pequeño no significa que siempre funcionará bien. Probemos de nuevo con otra imagen que no se haya probado antes. El ojo humano puede distinguir fácilmente de qué color es. Pero, ¿el modelo que parece estar funcionando perfectamente hasta ahora podrá clasificarlo correctamente?\n",
    "\n",
    "<img src = \"images/cardtestagain.png\" style = \"width: 400px; float: left;\" />\n",
    "<div style = \"clear: both;\"> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red\n"
     ]
    }
   ],
   "source": [
    "imagenew = cv2.imread(\"images/cardtestagain.png\")\n",
    "imagenew_features = averagecolor(imagenew)\n",
    "prediction = (model.predict([imagenew_features])[0])\n",
    "\n",
    "#decode the prediction from numerical to labels\n",
    "print(encoder.inverse_transform([prediction])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué salió mal?\n",
    "\n",
    "Desafortunadamente, la imagen parece estar mal clasificada como verde en lugar de roja. <br />\n",
    "Sería difícil profundizar en por qué el modelo SVM se clasificó incorrectamente en este caso sin profundizar en las matemáticas que están fuera del alcance de este taller. Una analogía simple sería que podría ser difícil intentar ajustar una curva en la ecuación de una línea recta. Así como y = mx + c sería la ecuación incorrecta para usar en una curva.\n",
    "\n",
    "** Sugerencia adicional: ** Al diseñar soluciones con aprendizaje automático, intente entrenar el modelo más preciso, pero también tómese un tiempo para planificar las contingencias cuando el modelo puede no dar el resultado correcto. También considere cuáles podrían ser los impactos de resultados incorrectos en su aplicación y tome medidas para mitigar los riesgos. Por ejemplo, si se trata de una máquina guiada por visión por computadora, ¿existen otros sensores que también se pueden usar para activar una parada de emergencia antes de que choque contra algo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mientras tanto, ¿qué piensa nuestro algoritmo kNN sobre la misma imagen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red\n"
     ]
    }
   ],
   "source": [
    "calculated_distances = []\n",
    "for card in (trainX2):\n",
    "    calculated_distances.append(np.linalg.norm(imagenew_features-card))\n",
    "print(trainY2[np.argmin(calculated_distances)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Eso significa que kNN siempre es más confiable?\n",
    "\n",
    "Probemos una imagen más:\n",
    "\n",
    "<img src = \"images/cardtestagain2.png\" style = \"width: 400px; float: left;\" />\n",
    "<div style = \"clear: both;\"> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: none\n",
      "kNN: none\n"
     ]
    }
   ],
   "source": [
    "imagenew = cv2.imread(\"images/cardtestagain2.png\")\n",
    "imagenew_features = averagecolor(imagenew)\n",
    "calculated_distances = []\n",
    "for card in (trainX2):\n",
    "    calculated_distances.append(np.linalg.norm(imagenew_features-card))\n",
    "    \n",
    "print(\"SVM: \"+str(encoder.inverse_transform([ model.predict([imagenew_features])[0] ])[0]))\n",
    "print(\"kNN: \"+str(trainY2[np.argmin(calculated_distances)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la imagen de arriba, ¿puedes adivinar por qué kNN clasificó erróneamente el algoritmo como ninguno en lugar de verde?\n",
    "\n",
    "Puede calcular el color promedio de la imagen para averiguar por qué.\n",
    "\n",
    "Y sí, puede entrenar el modelo con más imágenes para mitigar estos problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Nota: Las matemáticas detrás de SVM estarán fuera del alcance de este taller, pero se le anima a leer más. https://www.svm-tutorial.com/2014/11/svm-understanding-math-part-1/ _ (En el enlace, se ilustra con diagramas cómo un solo vector lineal puede separar 2 clases distintas)\n",
    "\n",
    "En nuestro experimento, sin embargo, lo usamos para separar más de 2 clases. Puede obtener más información sobre la clasificación de clases múltiples usando SVM y ver ejemplos de código usando la documentación en https://scikit-learn.org/stable/modules/svm.html#multi-class-classification Y recuerde buscar en Internet si necesita más ayuda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¡Felicidades!\n",
    "\n",
    "## ¡Es hora de que hagas algunas prácticas!\n",
    "\n",
    "Ha completado una introducción muy rápida al aprendizaje automático y ha visto la progresión de un enfoque basado en reglas a un enfoque de aprendizaje automático. También ha utilizado datos de entrenamiento para entrenar los modelos kNN y SVM para la clasificación, y ha visto los resultados, así como algunas limitaciones. Ciertamente hay mucho más que aprender, ¡pero ya puedes empezar a construir!\n",
    "\n",
    "Siempre que necesite ayuda, siempre puede buscar en su amigable Internet. Aquí hay algunos enlaces rápidos para ayudar: <br />\n",
    "- https://docs.opencv.org/4.0.0/d2/d96/tutorial_py_table_of_contents_imgproc.html\n",
    "- https://scikit-learn.org/stable/documentation.html\n",
    "\n",
    "** Consejo: ** Recuerde las técnicas básicas de visión por computadora que aprendió en el taller anterior. Puede utilizarlos mientras piensa en las funciones que serían útiles para incorporar a su modelo. Espacios de color, umbralización, detección de contornos, transformaciones geométricas, manipulación directa de matrices de imágenes numerosas y más. A veces, los métodos básicos pueden ser los más efectivos para la tarea en cuestión.\n",
    "\n",
    "Independientemente de lo que construya, tenga en cuenta su propósito y objetivo y piense en diferentes enfoques posibles. También tenga en cuenta los posibles impactos cuando un algoritmo de aprendizaje automático realiza una clasificación errónea y planifique formas de mitigar los riesgos. Por ejemplo, si sabe que su modelo identifica muy bien las tarjetas rojas, pero a veces mezcla tarjetas verdes y azules, es posible que desee diseñar una solución utilizando tarjetas rojas en lugar de verdes y azules. Y puede agregar otras capas de verificación, por ejemplo, si se detecta una tarjeta verde / negra, solicitar que el personal de seguridad realice una verificación de segunda capa.\n",
    "\n",
    "Al igual que con otros escenarios en los que puede haber una probabilidad de error, explore la posibilidad de complementar el diseño de sus soluciones del mundo real con otras técnicas o sensores de hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desafío 1: ¿Cuál es el color promedio de \"images / test / 58.png\"?\n",
    "\n",
    "¿Recuerda que inicialmente se clasificó incorrectamente? Exploremos por qué.\n",
    "Almacene el resultado en una variable \"cha1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208.77603841 223.6275293  120.75616536]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image_58 = cv2.imread(\"images/test/58.png\")\n",
    "cha1 =# Su código aquí\n",
    "print (cha1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reto 2: ¿Cuál es el color promedio de \"images / background.png\"?\n",
    "\n",
    "Almacene el resultado en una variable \"cha2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[247.9326888  241.13666016 241.89832357]\n"
     ]
    }
   ],
   "source": [
    "# Su código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desafío 3: ¿Cuál es el color promedio de \"images / cardgreen_close.png\"?\n",
    "\n",
    "Almacene el resultado en una variable \"cha3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119.53976563 133.40338216  61.1089388 ]\n"
     ]
    }
   ],
   "source": [
    "# Su código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desafío 4: 58.png vs Fondo. Calcula la distancia entre cha1 y cha2\n",
    "\n",
    "Recuerde cómo se calculó la distancia euclidiana en la sección 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.51161592391296"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Su código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desafío 5: 58.png vs Green. Calcula la distancia entre cha1 y cha3\n",
    "\n",
    "Recuerde cómo se calculó la distancia euclidiana en la sección 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140.2187603130577"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Su código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Es menor la distancia en el desafío 4 (58.png frente al fondo) o la distancia en el desafío 5 (58.png frente a verde)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una distancia menor implica una mayor similitud. Por lo tanto, 58.png se clasificó como más similar al fondo que a la tarjeta verde en base a las 4 \"imágenes de entrenamiento\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¡Felicidades!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
